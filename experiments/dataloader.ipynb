{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pointnet2_ops import pointnet2_utils\n",
    "from knn_cuda import KNN\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D PCD: Importing, Downsampling and Saving as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Open3D point cloud\n",
      "PCD Details:\n",
      "PointCloud with 3305027 points.\n",
      "Every 100th points are selected, could use voxel or uniform downsampling\n",
      "(314410, 3)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Open3D point cloud\")\n",
    "path = \"../dataset/OldDataset/Barn_is/Barn/Barn02.ply\"\n",
    "pcd = o3d.io.read_point_cloud(path)\n",
    "print(\"PCD Details:\")\n",
    "print(pcd)\n",
    "\n",
    "# Link: https://www.open3d.org/docs/latest/tutorial/Advanced/pointcloud_outlier_removal.html\n",
    "print(\"Every 100th points are selected, could use voxel or uniform downsampling\")\n",
    "down_pcd = pcd.voxel_down_sample(voxel_size=0.001)\n",
    "# down_pcd = pcd.uniform_down_sample(every_k_points=10)\n",
    "\n",
    "#Link: https://www.open3d.org/html/tutorial/Basic/working_with_numpy.html\n",
    "np_pcd = np.asarray(down_pcd.points)\n",
    "print(np_pcd.shape)\n",
    "\n",
    "\n",
    "print(os.path.exists(path[:-10]))\n",
    "np.save(path[:-3] + \"npy\", np_pcd)\n",
    "\n",
    "#Visualise PCD\n",
    "o3d.visualization.draw_geometries([down_pcd])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using fps to make Nx3 to npointx3(usually 8192x3) \n",
    "def farthest_point_sample(point, npoint):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        xyz: pointcloud data, [N, D]\n",
    "        npoint: number of samples\n",
    "    Return:\n",
    "        centroids: sampled pointcloud index, [npoint, D]\n",
    "    \"\"\"\n",
    "    N, D = point.shape\n",
    "    xyz = point[:,:3]\n",
    "    centroids = np.zeros((npoint,))\n",
    "    distance = np.ones((N,)) * 1e10\n",
    "    farthest = np.random.randint(0, N)\n",
    "    for i in range(npoint):\n",
    "        centroids[i] = farthest\n",
    "        centroid = xyz[farthest, :]\n",
    "        dist = np.sum((xyz - centroid) ** 2, -1)\n",
    "        mask = dist < distance\n",
    "        distance[mask] = dist[mask]\n",
    "        farthest = np.argmax(distance, -1)\n",
    "    point = point[centroids.astype(np.int32)]\n",
    "    return point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepping 8192x3 float tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16384, 3)\n",
      "(8192, 3)\n",
      "Loaded point cloud of shape torch.float32\n"
     ]
    }
   ],
   "source": [
    "path = \"../dataset/Dataset/pcd/Barn02.npy\"\n",
    "np_pcd = np.load(path)\n",
    "\n",
    "print(np_pcd.shape)\n",
    "\n",
    "fps_pcd = farthest_point_sample(np_pcd , 8192)\n",
    "print(fps_pcd.shape)\n",
    "\n",
    "\n",
    "tensor_pcd = torch.from_numpy(np.reshape(fps_pcd, (1, fps_pcd.shape[0], fps_pcd.shape[1]))).to(device).cuda().float()\n",
    "\n",
    "print(\"Loaded point cloud of shape\", tensor_pcd.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer (nn.Module):\n",
    "    def __init__(self, num_group, group_size):\n",
    "        super().__init__()\n",
    "        self.num_group = num_group\n",
    "        self.group_size = group_size\n",
    "        self.knn = KNN(k=self.group_size, transpose_mode=True)\n",
    "\n",
    "    def forward(self, xyz):\n",
    "            '''\n",
    "                input: B N 3\n",
    "                ---------------------------\n",
    "                output: B G M 3\n",
    "                center : B G 3\n",
    "            '''\n",
    "            batch_size, num_points, _ = xyz.shape\n",
    "            # fps the centers out\n",
    "            center = self.fps(xyz, self.num_group) # B G 3\n",
    "            # knn to get the neighborhood\n",
    "            _, idx = self.knn(xyz, center) # B G M\n",
    "            assert idx.size(1) == self.num_group\n",
    "            assert idx.size(2) == self.group_size\n",
    "            idx_base = torch.arange(0, batch_size, device=xyz.device).view(-1, 1, 1) * num_points\n",
    "            idx = idx + idx_base\n",
    "            idx = idx.view(-1)\n",
    "            neighborhood = xyz.view(batch_size * num_points, -1)[idx, :]\n",
    "            neighborhood = neighborhood.view(batch_size, self.num_group, self.group_size, 3).contiguous()\n",
    "            # normalize\n",
    "            neighborhood = neighborhood - center.unsqueeze(2)\n",
    "            return neighborhood, center\n",
    "    \n",
    "    def fps(self, data, number):\n",
    "        '''\n",
    "            data B N 3\n",
    "            number int\n",
    "        '''\n",
    "        # print(number)\n",
    "        # print(\"yoyoyo\",data.scalar_type())\n",
    "        fps_idx = pointnet2_utils.furthest_point_sample(data, number) \n",
    "        fps_data = pointnet2_utils.gather_operation(data.transpose(1, 2).contiguous(), fps_idx).transpose(1,2).contiguous()\n",
    "        print(fps_data)\n",
    "        return fps_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms for PointClouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "class PointcloudScaleAndTranslate(object):\n",
    "    def __init__(self, scale_low=2. / 3., scale_high=3. / 2., translate_range=0.2):\n",
    "        self.scale_low = scale_low\n",
    "        self.scale_high = scale_high\n",
    "        self.translate_range = translate_range\n",
    "\n",
    "    def __call__(self, pc):\n",
    "        bsize = pc.size()[0]\n",
    "        for i in range(bsize):\n",
    "            xyz1 = np.random.uniform(low=self.scale_low, high=self.scale_high, size=[3])\n",
    "            xyz2 = np.random.uniform(low=-self.translate_range, high=self.translate_range, size=[3])\n",
    "            \n",
    "            pc[i, :, 0:3] = torch.mul(pc[i, :, 0:3], torch.from_numpy(xyz1).float().cuda()) + torch.from_numpy(xyz2).float().cuda()\n",
    "            \n",
    "        return pc\n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        # data_transforms.PointcloudScale(),\n",
    "        # data_transforms.PointcloudRotate(),\n",
    "        # data_transforms.PointcloudRotatePerturbation(),\n",
    "        # data_transforms.PointcloudTranslate(),\n",
    "        # data_transforms.PointcloudJitter(),\n",
    "        # data_transforms.PointcloudRandomInputDropout(),\n",
    "        PointcloudScaleAndTranslate(),\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(32,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_pcd = train_transforms(tensor_pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ -4.3732,  -4.0375, -34.9515],\n",
      "         [-20.5198,  -4.7560, -35.4129],\n",
      "         [ -3.5903,   4.8602, -28.0963],\n",
      "         [-12.5905,  -1.1428, -29.4915],\n",
      "         [  3.3627,  -5.5521, -31.8151],\n",
      "         [ -4.4329,  -4.1252, -27.2561],\n",
      "         [-11.8513,  -5.5845, -35.6064],\n",
      "         [-19.1418,  -1.2476, -29.6718],\n",
      "         [-15.7147,  -4.7538, -31.9732],\n",
      "         [ -8.1887,  -3.9590, -31.0826],\n",
      "         [  0.1067,  -6.0192, -35.5275],\n",
      "         [ -1.3346,  -4.1177, -31.0832],\n",
      "         [ -2.7092,   0.3938, -28.8218],\n",
      "         [ -7.8919,  -5.6614, -35.5239],\n",
      "         [-11.9187,  -3.8655, -32.1039],\n",
      "         [-16.8353,  -5.4843, -35.5011],\n",
      "         [  3.9335,  -5.5425, -35.5261],\n",
      "         [ -4.7668,  -4.8317, -31.4273],\n",
      "         [-19.0940,  -4.2970, -31.5667],\n",
      "         [-15.8823,  -0.9626, -29.4315],\n",
      "         [ -9.6888,  -3.9202, -34.0051],\n",
      "         [ -1.6371,  -4.1008, -34.0073],\n",
      "         [  0.6305,  -5.4310, -32.7284],\n",
      "         [ -6.6380,  -4.9478, -28.9244],\n",
      "         [ -6.8028,  -3.9897, -33.5542],\n",
      "         [-14.3347,  -4.7531, -34.5144],\n",
      "         [-14.1527,  -3.1238, -30.5085],\n",
      "         [ -3.0436,  -4.8563, -29.2954],\n",
      "         [ -2.6736,  -5.9037, -35.5202],\n",
      "         [-17.1285,  -2.8145, -30.6212],\n",
      "         [  0.5313,  -5.4725, -30.2196],\n",
      "         [ -4.7044,  -0.8403, -28.0891]]], device='cuda:0')\n",
      "torch.Size([1, 32, 64, 3])\n",
      "torch.Size([1, 32, 3])\n"
     ]
    }
   ],
   "source": [
    "test = tokenizer.forward(tensor_pcd)\n",
    "\n",
    "print(test[0].shape)\n",
    "print(test[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional visualize numpy array pcds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "\n",
    "# Pass xyz to Open3D.o3d.geometry.PointCloud and visualize\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(np_pcd)\n",
    "o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "# o3d.io.write_point_cloud(\"../../TestData/sync.ply\", pcd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obitonet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
