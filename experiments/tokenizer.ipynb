{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinaylanka/miniconda3/envs/obitonet/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pointnet2_ops import pointnet2_utils\n",
    "from knn_cuda import KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load a ply point cloud, print it, and render it\n",
      "PointCloud with 1642571 points.\n"
     ]
    }
   ],
   "source": [
    "print(\"Load a ply point cloud, print it, and render it\")\n",
    "path = \"../dataset/OldDataset/Barn_is/Barn/Barn01.ply\"\n",
    "pcd = o3d.io.read_point_cloud(path)\n",
    "print(pcd)\n",
    "\n",
    "voxel_grid = o3d.geometry.VoxelGrid.create_from_point_cloud(pcd,\n",
    "                                                        voxel_size=0.01)\n",
    "voxels = voxel_grid.get_voxels()  # returns list of voxels\n",
    "indices = np.stack(list(vx.grid_index for vx in voxels))\n",
    "colors = np.stack(list(vx.color for vx in voxels))\n",
    "# print(indices[0:10])\n",
    "# print(voxel_grid)\n",
    "o3d.visualization.draw_geometries([voxel_grid])\n",
    "\n",
    "voxel_grid = o3d.geometry.VoxelGrid.create_from_point_cloud(pcd,\n",
    "                                                    voxel_size=0.2)\n",
    "voxels = voxel_grid.get_voxels()  # returns list of voxels\n",
    "indices = np.stack(list(vx.grid_index for vx in voxels))\n",
    "colors = np.stack(list(vx.color for vx in voxels))\n",
    "# print(indices[0:10])\n",
    "# print(voxel_grid)\n",
    "o3d.visualization.draw_geometries([voxel_grid])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer (nn.Module):\n",
    "    def __init__(self, num_group, group_size):\n",
    "        super().__init__()\n",
    "        self.num_group = num_group\n",
    "        self.group_size = group_size\n",
    "        self.knn = KNN(k=self.group_size, transpose_mode=True)\n",
    "        self.mask_ratio = 0.6\n",
    "\n",
    "    def forward(self, xyz):\n",
    "            '''\n",
    "                input: B N 3\n",
    "                ---------------------------\n",
    "                output: B G M 3\n",
    "                center : B G 3\n",
    "            '''\n",
    "            batch_size, num_points, _ = xyz.shape\n",
    "            # fps the centers out\n",
    "            center = self.fps(xyz, self.num_group) # B G 3\n",
    "            # knn to get the neighborhood\n",
    "            _, idx = self.knn(xyz, center) # B G M\n",
    "            assert idx.size(1) == self.num_group\n",
    "            assert idx.size(2) == self.group_size\n",
    "            idx_base = torch.arange(0, batch_size, device=xyz.device).view(-1, 1, 1) * num_points\n",
    "            idx = idx + idx_base\n",
    "            idx = idx.view(-1)\n",
    "            neighborhood = xyz.view(batch_size * num_points, -1)[idx, :]\n",
    "            neighborhood = neighborhood.view(batch_size, self.num_group, self.group_size, 3).contiguous()\n",
    "            # normalize\n",
    "            neighborhood = neighborhood - center.unsqueeze(2)\n",
    "            return neighborhood, center\n",
    "    \n",
    "    def masking(self, center, noaug = False):\n",
    "        '''\n",
    "            center : B G 3\n",
    "            --------------\n",
    "            mask : B G (bool)\n",
    "        '''\n",
    "        B, G, _ = center.shape\n",
    "        # skip the mask\n",
    "        if noaug or self.mask_ratio == 0:\n",
    "            return torch.zeros(center.shape[:2]).bool()\n",
    "\n",
    "        self.num_mask = int(self.mask_ratio * G)\n",
    "\n",
    "        overall_mask = np.zeros([B, G])\n",
    "        for i in range(B):\n",
    "            mask = np.hstack([\n",
    "                np.zeros(G-self.num_mask),\n",
    "                np.ones(self.num_mask),\n",
    "            ])\n",
    "            np.random.shuffle(mask)\n",
    "            overall_mask[i, :] = mask\n",
    "        overall_mask = torch.from_numpy(overall_mask).to(torch.bool)\n",
    "\n",
    "        return overall_mask.to(center.device) # B G\n",
    "    \n",
    "    def fps(self, data, number):\n",
    "        '''\n",
    "            data B N 3\n",
    "            number int\n",
    "        '''\n",
    "        # print(number)\n",
    "        # print(\"yoyoyo\",data.scalar_type())\n",
    "        fps_idx = pointnet2_utils.furthest_point_sample(data, number) \n",
    "        fps_data = pointnet2_utils.gather_operation(data.transpose(1, 2).contiguous(), fps_idx).transpose(1,2).contiguous()\n",
    "        print(fps_data)\n",
    "        return fps_data\n",
    "    \n",
    "def farthest_point_sample(point, npoint):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        xyz: pointcloud data, [N, D]\n",
    "        npoint: number of samples\n",
    "    Return:\n",
    "        centroids: sampled pointcloud index, [npoint, D]\n",
    "    \"\"\"\n",
    "    N, D = point.shape\n",
    "    xyz = point[:,:3]\n",
    "    centroids = np.zeros((npoint,))\n",
    "    distance = np.ones((N,)) * 1e10\n",
    "    farthest = np.random.randint(0, N)\n",
    "    for i in range(npoint):\n",
    "        centroids[i] = farthest\n",
    "        centroid = xyz[farthest, :]\n",
    "        dist = np.sum((xyz - centroid) ** 2, -1)\n",
    "        mask = dist < distance\n",
    "        distance[mask] = dist[mask]\n",
    "        farthest = np.argmax(distance, -1)\n",
    "    point = point[centroids.astype(np.int32)]\n",
    "    return point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(32,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "class PointcloudScaleAndTranslate(object):\n",
    "    def __init__(self, scale_low=2. / 3., scale_high=3. / 2., translate_range=0.2):\n",
    "        self.scale_low = scale_low\n",
    "        self.scale_high = scale_high\n",
    "        self.translate_range = translate_range\n",
    "\n",
    "    def __call__(self, pc):\n",
    "        bsize = pc.size()[0]\n",
    "        for i in range(bsize):\n",
    "            xyz1 = np.random.uniform(low=self.scale_low, high=self.scale_high, size=[3])\n",
    "            xyz2 = np.random.uniform(low=-self.translate_range, high=self.translate_range, size=[3])\n",
    "            \n",
    "            pc[i, :, 0:3] = torch.mul(pc[i, :, 0:3], torch.from_numpy(xyz1).float().cuda()) + torch.from_numpy(xyz2).float().cuda()\n",
    "            \n",
    "        return pc\n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        # data_transforms.PointcloudScale(),\n",
    "        # data_transforms.PointcloudRotate(),\n",
    "        # data_transforms.PointcloudRotatePerturbation(),\n",
    "        # data_transforms.PointcloudTranslate(),\n",
    "        # data_transforms.PointcloudJitter(),\n",
    "        # data_transforms.PointcloudRandomInputDropout(),\n",
    "        PointcloudScaleAndTranslate(),\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16384, 3)\n"
     ]
    }
   ],
   "source": [
    "path = \"../dataset/Dataset/pcd/Barn01.npy\"\n",
    "np_pcd = np.load(path)\n",
    "\n",
    "print(np_pcd.shape)\n",
    "tensor_pcd = torch.from_numpy(np.reshape(np_pcd, (1, np_pcd.shape[0], np_pcd.shape[1]))).to(device).cuda().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_pcd = train_transforms(tensor_pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  3.8867,  -7.0483, -23.3645],\n",
      "         [-21.4999,  -5.5777, -21.4391],\n",
      "         [ -4.6564,   7.9825, -18.5496],\n",
      "         ...,\n",
      "         [  2.3679,  -7.2225, -23.5431],\n",
      "         [  2.3936,  -7.2203, -21.9857],\n",
      "         [  3.8669,  -6.3027, -23.6986]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(tensor_pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 3.8867e+00, -7.0483e+00, -2.3364e+01],\n",
      "         [-2.1500e+01, -5.5777e+00, -2.1439e+01],\n",
      "         [-4.6564e+00,  7.9825e+00, -1.8550e+01],\n",
      "         [-9.0250e+00, -7.4897e+00, -2.4175e+01],\n",
      "         [ 4.6501e+00,  4.5830e+00, -2.4156e+01],\n",
      "         [-2.8450e+00, -1.5664e+00, -1.9275e+01],\n",
      "         [-1.5544e+01, -6.5998e+00, -2.4178e+01],\n",
      "         [-2.5397e+00, -5.9901e+00, -2.4146e+01],\n",
      "         [ 3.3715e+00, -9.5880e-01, -2.1403e+01],\n",
      "         [ 5.9040e-02,  4.3668e+00, -2.0219e+01],\n",
      "         [-5.8925e+00, -6.3627e+00, -1.9787e+01],\n",
      "         [ 4.8794e+00,  9.7736e+00, -2.4150e+01],\n",
      "         [-1.2012e+01, -5.1754e+00, -2.1011e+01],\n",
      "         [-4.7247e+00,  2.8751e+00, -1.8567e+01],\n",
      "         [ 6.0323e-01, -4.9373e+00, -2.0487e+01],\n",
      "         [-1.5960e+01, -4.2331e+00, -2.0916e+01],\n",
      "         [ 4.5705e+00, -3.3100e+00, -2.4168e+01],\n",
      "         [ 3.6931e+00,  7.3881e+00, -2.1448e+01],\n",
      "         [-6.0736e+00, -5.2796e+00, -2.3380e+01],\n",
      "         [-4.1025e-01,  7.9603e+00, -2.0008e+01],\n",
      "         [ 3.1194e+00,  2.7374e+00, -2.1284e+01],\n",
      "         [ 4.6787e+00,  9.7903e-01, -2.4155e+01],\n",
      "         [-2.1070e-02,  4.1857e-01, -2.0243e+01],\n",
      "         [ 5.2860e-01, -7.9230e+00, -2.4183e+01],\n",
      "         [-1.9403e+01, -6.1885e+00, -2.4098e+01],\n",
      "         [-2.6071e+00, -5.4467e+00, -1.9435e+01],\n",
      "         [-1.2197e+01, -6.1832e+00, -2.4208e+01],\n",
      "         [-2.6674e+00,  5.6276e+00, -1.9269e+01],\n",
      "         [-8.9581e+00, -5.4371e+00, -2.1737e+01],\n",
      "         [ 3.3742e+00, -4.1638e+00, -2.1449e+01],\n",
      "         [-4.9010e+00, -3.5289e+00, -1.8562e+01],\n",
      "         [ 2.1697e+00, -7.3065e+00, -2.1051e+01]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "test, centers = tokenizer.forward(tensor_pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 128, 3])\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)\n",
    "\n",
    "# print(test[0].shape)\n",
    "# print(test[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_patch = test.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "print(pcd_patch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "\n",
    "# Pass xyz to Open3D.o3d.geometry.PointCloud and visualize\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(pcd_patch[0][31])\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_masked_pos = tokenizer.masking(centers, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False,  True,  True,  True,  True, False,  True, False,  True, False,\n",
      "          True, False,  True, False, False,  True, False,  True, False,  True,\n",
      "          True,  True,  True,  True,  True, False, False, False,  True,  True,\n",
      "         False,  True]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(bool_masked_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_input_tokens = self.encoder(neighborhood)  #  B G C\n",
    "\n",
    "batch_size, seq_len, C = group_input_tokens.size()\n",
    "\n",
    "x_vis = group_input_tokens[~bool_masked_pos].reshape(batch_size, -1, C)\n",
    "# add pos embedding\n",
    "# mask pos center\n",
    "masked_center = center[~bool_masked_pos].reshape(batch_size, -1, 3)\n",
    "pos = self.pos_embed(masked_center)\n",
    "\n",
    "# transformer\n",
    "x_vis = self.blocks(x_vis, pos)\n",
    "x_vis = self.norm(x_vis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obitonet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
